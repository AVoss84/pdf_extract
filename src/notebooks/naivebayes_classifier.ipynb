{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from Pdf documents and apply NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Variable: UC_CODE_DIR has been set to default: /home/alexv84/Documents/GitHub/pdf_extract/src\n",
      "Environment Variable: UC_DATA_DIR has been set to default: /home/alexv84/Documents/Arbeit/Allianz/AZVers/data\n",
      "Environment Variable: UC_LANG_ID has been set to default: /home/alexv84/Documents/Arbeit/Allianz/AZVers/fasttext_langdetect\n",
      "Environment Variable: UC_DATA_PKG_DIR has been set to default: \n",
      "Environment Variable: UC_DB_CONNECTION has been set to default: postgresql://postgres...\n",
      "Environment Variable: UC_PORT has been set to default: 5000\n",
      "Environment Variable: UC_APP_CONNECTION has been set to default: 127.0.0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'pdf_extract.services.file' from '/home/alexv84/Documents/GitHub/pdf_extract/src/pdf_extract/services/file.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfplumber, os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pdf_extract.services import file\n",
    "from pdf_extract.config import global_config as glob\n",
    "from pdf_extract.config import config\n",
    "from pdf_extract.utils import utils\n",
    "from importlib import reload\n",
    "import fasttext\n",
    "\n",
    "reload(glob)\n",
    "reload(config)\n",
    "reload(utils)\n",
    "reload(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "list_of_NEG_docs = os.listdir(osp.join(glob.UC_DATA_DIR, 'example_cvs', 'negatives'))\n",
    "n_neg = len(list_of_NEG_docs)\n",
    "\n",
    "list_of_POS_docs = os.listdir(osp.join(glob.UC_DATA_DIR, 'example_cvs', 'positives'))\n",
    "n_pos = len(list_of_POS_docs)\n",
    "\n",
    "print(n_pos)\n",
    "print(n_neg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in all Pdfs in directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postives only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus1 = pd.DataFrame(columns=['text', 'label'])\n",
    "\n",
    "for z, fname in enumerate(list_of_POS_docs):\n",
    "    #print(fname)\n",
    "    i, page_objects, text = 0, {}, \"\"\n",
    "    # The open method returns an instance of the pdfplumber.PDF class.\n",
    "    with pdfplumber.open(osp.join(glob.UC_DATA_DIR, \"example_cvs\",f\"positives/{fname}\")) as pdf:\n",
    "        while i < len(pdf.pages):\n",
    "            page = pdf.pages[i]\n",
    "            page_objects[str(i+1)] = page.extract_text(x_tolerance=1, y_tolerance=3) #.split('\\n')\n",
    "            text += page_objects[str(i+1)]\n",
    "            #print(f\"Page {i}\")\n",
    "            #print(page.extract_text())\n",
    "            i += 1\n",
    "    \n",
    "    raw_corpus1.loc[z] = text  \n",
    "raw_corpus1['label'] = 'positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negatives only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus2 = pd.DataFrame(columns=['text','label'])\n",
    "\n",
    "for z, fname in enumerate(list_of_NEG_docs):\n",
    "    #print(fname)\n",
    "    i, page_objects, text = 0, {}, \"\"\n",
    "    # The open method returns an instance of the pdfplumber.PDF class.\n",
    "    with pdfplumber.open(osp.join(glob.UC_DATA_DIR, \"example_cvs\",f\"negatives/{fname}\")) as pdf:\n",
    "        while i < len(pdf.pages):\n",
    "            page = pdf.pages[i]\n",
    "            page_objects[str(i+1)] = page.extract_text(x_tolerance=1, y_tolerance=3) #.split('\\n')\n",
    "            text += page_objects[str(i+1)]\n",
    "            #print(f\"Page {i}\")\n",
    "            #print(page.extract_text())\n",
    "            i += 1\n",
    "    \n",
    "    raw_corpus2.loc[z] = text   \n",
    "raw_corpus2['label'] = 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus = pd.concat([raw_corpus1,raw_corpus2], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_objects\n",
    "\n",
    "#page.extract_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_instance = page_objects['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf.metadata\n",
    "#page_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess text corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using english language.\n",
      "Using 179 stop words.\n",
      "Added 0 stopword(s).\n",
      "Adding custom stop words...\n",
      "Setting to lower cases.\n",
      "Removing whitespaces.\n",
      "Applying word tokenizer.\n",
      "Removing custom stopwords.\n",
      "Removing punctuations.\n",
      "Removing numbers.\n",
      "Removing digits.\n",
      "Removing non-alphabetic characters.\n",
      "Removing short tokens.\n",
      "Finished preprocessing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alexv84/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/alexv84/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/alexv84/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/alexv84/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pdf_extract.resources import preprocessor as preproc\n",
    "\n",
    "reload(preproc)\n",
    "\n",
    "# Preprocess corpus:\n",
    "cleaner = preproc.clean_text(language='english', lemma = False, stem = False)\n",
    "\n",
    "X = raw_corpus['text']\n",
    "\n",
    "X_cl = cleaner.fit_transform(X)\n",
    "#docs = X_cl.tolist()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus['text_cleaned'] = X_cl\n",
    "X = raw_corpus[['label', 'text_cleaned']].reset_index(drop=True)\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reload(utils)\n",
    "\n",
    "#X_train, X_valid, X_test, y_train, y_valid, y_test = utils.train_test_split_extend(X['text_cleaned'], y=X['label'], test_size=[0.2, 0.2], random_state=42, shuffle=True)\n",
    "X_train, X_test, y_train, y_test = utils.train_test_split_extend(X['text_cleaned'], y=X['label'], test_size=[0.4], random_state=123, shuffle=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "#print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "#print(X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "    # 'vectorizer__max_features': (None, 5000, 10000, 50000),\n",
    "    'vectorizer__ngram_range': ((2, 2), (1, 3), (2, 3), (3, 3), (3, 5))  # unigrams or bigrams\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "   #('cleaner', utils.clean_text(verbose=False)),\n",
    "   ('vectorizer', CountVectorizer(lowercase=True, \n",
    "                       token_pattern = '(?u)(?:(?!\\d)\\w)+\\\\w+', analyzer = 'word', tokenizer = None, stop_words = None)), \n",
    "   #('scaler', StandardScaler(with_mean=False)),\n",
    "   ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "gs = grid_search.fit(X_train, y_train)\n",
    "\n",
    "#vect = pipeline.fit_transform(X['text_cleaned'], X['fasttext_label'])\n",
    "\n",
    "#pipeline.fit(X['text_cleaned'], X['fasttext_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "# best_model refit:\n",
    "trained = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle Service Read from file: /home/alexv84/Documents/Arbeit/Allianz/AZVers/data/trained_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#-------------\n",
    "# Save model:\n",
    "#-------------\n",
    "file.PickleService(path=\"trained_model.pkl\", root_path=glob.UC_DATA_DIR, is_df=False).doWrite(X=trained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00         8\n",
      "    positive       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict:\n",
    "y_pred = trained.predict(X_train)\n",
    "\n",
    "#print(confusion_matrix(test_set['label'], y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.40      0.57         5\n",
      "    positive       0.62      1.00      0.77         5\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.81      0.70      0.67        10\n",
      "weighted avg       0.81      0.70      0.67        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict:\n",
    "y_pred = trained.predict(X_test)\n",
    "\n",
    "#print(confusion_matrix(test_set['label'], y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prob. positive class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.999880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.989767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.932621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.878249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.089161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prob. positive class\n",
       "0              1.000000\n",
       "3              0.999999\n",
       "8              0.999977\n",
       "6              0.999880\n",
       "4              0.999499\n",
       "7              0.989767\n",
       "1              0.932621\n",
       "9              0.878249\n",
       "5              0.089161\n",
       "2              0.034649"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probs = pd.DataFrame(trained.predict_proba(X_test)[:,1], columns=['Prob. positive class'])\n",
    "class_probs.sort_values(by = 'Prob. positive class', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('env_pdf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d49ecafdcaaa7827583b5b21ff598afa0c2165a9797f363685e472c1c2a4bb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
